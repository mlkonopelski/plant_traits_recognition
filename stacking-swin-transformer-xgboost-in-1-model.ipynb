{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":65626,"databundleVersionId":8046133,"sourceType":"competition"}],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 1.1. Libraries","metadata":{}},{"cell_type":"code","source":"# Utils\nfrom dataclasses import dataclass\nimport os\nimport psutil\nfrom tqdm.notebook import tqdm\nfrom typing import List\nimport time\n\n# EDA & DATA\nimport imageio.v3 as imageio\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\n\n# ML\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport timm\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torchmetrics\nfrom xgboost import XGBRegressor\nimport xgboost as xgb\n\n\ntqdm.pandas()","metadata":{"execution":{"iopub.status.busy":"2024-04-17T20:19:58.774861Z","iopub.execute_input":"2024-04-17T20:19:58.775522Z","iopub.status.idle":"2024-04-17T20:19:58.782616Z","shell.execute_reply.started":"2024-04-17T20:19:58.775488Z","shell.execute_reply":"2024-04-17T20:19:58.781589Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\nDEVICE","metadata":{"execution":{"iopub.status.busy":"2024-04-17T17:56:10.367916Z","iopub.execute_input":"2024-04-17T17:56:10.368230Z","iopub.status.idle":"2024-04-17T17:56:10.400331Z","shell.execute_reply.started":"2024-04-17T17:56:10.368203Z","shell.execute_reply":"2024-04-17T17:56:10.399098Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"markdown","source":"# 2. Data","metadata":{}},{"cell_type":"markdown","source":"# 2.1. Read files","metadata":{}},{"cell_type":"code","source":"DATAPATH = '/kaggle/input/planttraits2024'","metadata":{"execution":{"iopub.status.busy":"2024-04-17T17:56:10.401505Z","iopub.execute_input":"2024-04-17T17:56:10.401841Z","iopub.status.idle":"2024-04-17T17:56:10.412973Z","shell.execute_reply.started":"2024-04-17T17:56:10.401802Z","shell.execute_reply":"2024-04-17T17:56:10.412132Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(DATAPATH + '/train.csv')\ntrain['file_path'] = train['id'].apply(lambda s: DATAPATH + f'/train_images/{s}.jpeg')\ntrain['jpeg_bytes'] = train['file_path'].progress_apply(lambda fp: open(fp, 'rb').read())","metadata":{"execution":{"iopub.status.busy":"2024-04-17T17:56:19.505410Z","iopub.execute_input":"2024-04-17T17:56:19.505870Z","iopub.status.idle":"2024-04-17T18:03:28.193206Z","shell.execute_reply.started":"2024-04-17T17:56:19.505837Z","shell.execute_reply":"2024-04-17T18:03:28.192203Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/55489 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77a97014cd6541c2a4c2a7e1f54a589e"}},"metadata":{}}]},{"cell_type":"code","source":"test = pd.read_csv(DATAPATH + '/test.csv', nrows=0)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T18:03:32.707920Z","iopub.execute_input":"2024-04-17T18:03:32.708602Z","iopub.status.idle":"2024-04-17T18:03:32.745396Z","shell.execute_reply.started":"2024-04-17T18:03:32.708567Z","shell.execute_reply":"2024-04-17T18:03:32.744612Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"all_test_cols = list(set(train.columns).difference(test.columns))\ntrain_cols = [col for col in train.columns if col not in ['id'] + all_test_cols]\ntest_cols = ['X4_mean', 'X11_mean', 'X18_mean', 'X50_mean', 'X26_mean', 'X3112_mean']","metadata":{"execution":{"iopub.status.busy":"2024-04-17T19:23:18.885057Z","iopub.execute_input":"2024-04-17T19:23:18.885411Z","iopub.status.idle":"2024-04-17T19:23:18.890825Z","shell.execute_reply.started":"2024-04-17T19:23:18.885375Z","shell.execute_reply":"2024-04-17T19:23:18.889907Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":"## 2.2. Clean outliers","metadata":{}},{"cell_type":"code","source":"print(f'Before cleaning df has {train.shape[0]} rows')\nfor col in test_cols:\n    q_low = train[col].quantile(0.01)\n    q_hi  = train[col].quantile(0.99)\n    rows = train.shape[0]\n    train = train[(train[col] < q_hi) & (train[col] > q_low)]\n    print(f'\\tCleaning: {col} removed {rows - train.shape[0]} rows')\nprint(f'After cleaning df has {train.shape[0]} rows')","metadata":{"execution":{"iopub.status.busy":"2024-04-17T18:03:36.764392Z","iopub.execute_input":"2024-04-17T18:03:36.765060Z","iopub.status.idle":"2024-04-17T18:03:37.014546Z","shell.execute_reply.started":"2024-04-17T18:03:36.765026Z","shell.execute_reply":"2024-04-17T18:03:37.013608Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Before cleaning df has 55489 rows\n\tCleaning: X4_mean removed 1113 rows\n\tCleaning: X11_mean removed 1090 rows\n\tCleaning: X18_mean removed 1067 rows\n\tCleaning: X50_mean removed 1047 rows\n\tCleaning: X26_mean removed 1026 rows\n\tCleaning: X3112_mean removed 1007 rows\nAfter cleaning df has 49139 rows\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## 2.4. Create datasets & dataloaders","metadata":{}},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, df, y_cols: List[str], transforms=None):\n        self.ys = df[y_cols].values\n        self.img_col = 'jpeg_bytes'\n        self.imgs = df[self.img_col].values\n        \n        self.row_cols = [col for col in train_cols if col not in ('id', 'file_path', self.img_col)]\n        self.rows = df[self.row_cols].values\n        \n        self.transforms = transforms\n        \n        \n    def __len__(self):\n        return len(self.imgs)\n\n    def __getitem__(self, ix):\n\n        row = self.rows[ix]\n        img = imageio.imread(self.imgs[ix])\n        if self.transforms:\n            img = self.transforms(image=img)['image']\n        else:\n            img = torch.from_numpy(img)\n        y = self.ys[ix]\n\n        return row, img, y","metadata":{"execution":{"iopub.status.busy":"2024-04-17T18:03:42.093766Z","iopub.execute_input":"2024-04-17T18:03:42.094633Z","iopub.status.idle":"2024-04-17T18:03:42.102658Z","shell.execute_reply.started":"2024-04-17T18:03:42.094578Z","shell.execute_reply":"2024-04-17T18:03:42.101678Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# 3. Model","metadata":{}},{"cell_type":"code","source":"@dataclass\nclass CONFIG:\n    BACKBONE = 'swin_large_patch4_window12_384.ms_in22k_ft_in1k'\n    TARGET_COLUMNS = ['X4_mean', 'X11_mean', 'X18_mean', 'X50_mean', 'X26_mean', 'X3112_mean']\n    N_TARGETS = len(TARGET_COLUMNS)\n    BATCH_SIZE = 10\n    LR_MAX = 1e-4\n    WEIGHT_DECAY = 0.01\n    N_EPOCHS = 1\n    TRAIN_MODEL = True\n    IS_INTERACTIVE = os.environ['KAGGLE_KERNEL_RUN_TYPE'] == 'Interactive'\n    \n    N_TRAIN_SAMPLES = len(train)\n    N_STEPS_PER_EPOCH = (N_TRAIN_SAMPLES // BATCH_SIZE)\n    N_STEPS = N_STEPS_PER_EPOCH * N_EPOCHS + 1","metadata":{"execution":{"iopub.status.busy":"2024-04-17T18:03:51.878702Z","iopub.execute_input":"2024-04-17T18:03:51.879076Z","iopub.status.idle":"2024-04-17T18:03:51.885704Z","shell.execute_reply.started":"2024-04-17T18:03:51.879045Z","shell.execute_reply":"2024-04-17T18:03:51.884609Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"data_config = timm.data.resolve_model_data_config(CONFIG.BACKBONE)\ntransforms = timm.data.create_transform(**data_config, is_training=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T18:03:53.601514Z","iopub.execute_input":"2024-04-17T18:03:53.602190Z","iopub.status.idle":"2024-04-17T18:03:53.607334Z","shell.execute_reply.started":"2024-04-17T18:03:53.602159Z","shell.execute_reply":"2024-04-17T18:03:53.606389Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"CONFIG.IMAGE_SIZE = 384 #data_config['input_size'][1]\nCONFIG.IMAGE_MEAN = data_config['mean']\nCONFIG.IMAGE_STD = data_config['std']\nCONFIG.IMAGE_INTERPOLATION = data_config['interpolation']","metadata":{"execution":{"iopub.status.busy":"2024-04-17T18:03:56.975701Z","iopub.execute_input":"2024-04-17T18:03:56.976065Z","iopub.status.idle":"2024-04-17T18:03:56.981164Z","shell.execute_reply.started":"2024-04-17T18:03:56.976035Z","shell.execute_reply":"2024-04-17T18:03:56.979974Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"XGBOOST_PARAMS = {'random_state': 0,\n                  'multi_strategy' : \"one_output_per_tree\",\n                  'tree_method': 'hist', #'exact',\n                  'booster' : \"gbtree\",\n                  'eval_metric' : \"rmse\",\n                  'objective': 'reg:squarederror',\n                  'colsample_bynode': 0.8274131159915409,\n                  'colsample_bytree': 0.6807728406101965,\n                  'gamma': 0.033759641187317335,\n                  'learning_rate': 0.057359495247975095,\n                  'max_depth': 9,\n                  'min_child_weight': 57,\n                  'reg_alpha': 1.9190306595715692,\n                  'reg_lambda': 10.477908255864408,\n                  'subsample': 0.7708761325192125,\n         }","metadata":{"execution":{"iopub.status.busy":"2024-04-17T20:33:19.514629Z","iopub.execute_input":"2024-04-17T20:33:19.515452Z","iopub.status.idle":"2024-04-17T20:33:19.521122Z","shell.execute_reply.started":"2024-04-17T20:33:19.515416Z","shell.execute_reply":"2024-04-17T20:33:19.520073Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"class ContinuesModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        self.backbone = timm.create_model(\n            CONFIG.BACKBONE,\n            num_classes=CONFIG.N_TARGETS,\n            pretrained=True)\n        self._init_xgboost()\n        self.weighted_join = nn.Linear(2*CONFIG.N_TARGETS, CONFIG.N_TARGETS)\n\n    def _init_xgboost(self):\n        sample_df = train.sample(n=100)\n        self.xgboost = xgb.train(XGBOOST_PARAMS,\n                         dtrain = xgb.DMatrix(sample_df[train_cols].values, sample_df[test_cols].values), num_boost_round=261\n                        )\n        add_params = {'updater':'refresh','process_type': 'update', 'refresh_leaf': True,}\n        self.params = dict(XGBOOST_PARAMS.items() + add_params.items())\n        \n    def forward(self, row, img, y):\n        if self.training:\n            self.xgboost = xgb.train(self.params, dtrain=xgb.DMatrix(row, y), xgb_model=self.xgboost)\n            row_path = self.xgboost.predict(xgb.DMatrix(row))\n        else:\n            row_path = self.xgboost.predict(xgb.DMatrix(row))\n                    \n        cat_path = torch.cat([img_path, row_path])\n        out = self.weighted_join(cat_path)\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-04-17T18:04:01.894732Z","iopub.execute_input":"2024-04-17T18:04:01.895093Z","iopub.status.idle":"2024-04-17T18:04:01.901580Z","shell.execute_reply.started":"2024-04-17T18:04:01.895064Z","shell.execute_reply":"2024-04-17T18:04:01.900307Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# model.train()\n\n# train_dataloader = DataLoader(\n#         train_dataset,\n#         batch_size=1000,\n#         shuffle=True,\n#         drop_last=True,\n# #         num_workers=psutil.cpu_count(),\n# )\n\n# for step, (row_batch, img_batch, y_true) in enumerate(train_dataloader):\n# #     img_batch = img_batch.to(DEVICE)\n#     y_true = y_true#.to(DEVICE)\n#     if model.training:\n#         test_xgboost = xgb.train(params,\n#                                  dtrain = xgb.DMatrix(row_batch, y_true.cpu()), \n#                                  num_boost_round=100,\n#                                  xgb_model=test_xgboost)\n#         row_path = test_xgboost.predict(xgb.DMatrix(row_batch))\n#         r2_ = r2_score(y_true, row_path)\n#         print(f'step:{step} {r2_}')\n#     if step == 20:\n#         break","metadata":{"execution":{"iopub.status.busy":"2024-04-17T20:21:23.695957Z","iopub.execute_input":"2024-04-17T20:21:23.696278Z","iopub.status.idle":"2024-04-17T20:21:23.700824Z","shell.execute_reply.started":"2024-04-17T20:21:23.696253Z","shell.execute_reply":"2024-04-17T20:21:23.699968Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"class ImageModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.backbone = timm.create_model(\n                CONFIG.BACKBONE,\n                num_classes=CONFIG.N_TARGETS,\n                pretrained=True)\n        \n    def forward(self, inputs):\n        return self.backbone(inputs)\n\n\nclass RegressionModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.model = XGBRegressor(**XGBOOST_PARAMS,\n                                  device=DEVICE, )\n\n    def forward(self, X_train, y_train):\n        return  model.fit(cp.array(X_train), cp.array(y_train))\n\n\nclass StackedModel(nn.Module):\n    def __init__(self, img_model, reg_model):\n        self.img_model = img_model\n        self.reg_model = reg_model\n        self.weighted_join = nn.Linear(2*CONFIG.N_TARGETS, CONFIG.N_TARGETS)\n\n    def forward(self, x):\n        out = torch.cat([\n            self.img_model(x),\n            self.r_model(x)\n        ])\n        out = self.weighted_join(out)\n        return out","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.3. Define Albumentations","metadata":{}},{"cell_type":"code","source":"data_config","metadata":{"execution":{"iopub.status.busy":"2024-04-17T20:20:48.095631Z","iopub.execute_input":"2024-04-17T20:20:48.096259Z","iopub.status.idle":"2024-04-17T20:20:48.102848Z","shell.execute_reply.started":"2024-04-17T20:20:48.096225Z","shell.execute_reply":"2024-04-17T20:20:48.101848Z"},"trusted":true},"execution_count":80,"outputs":[{"execution_count":80,"output_type":"execute_result","data":{"text/plain":"{'input_size': (3, 224, 224),\n 'interpolation': 'bicubic',\n 'mean': (0.485, 0.456, 0.406),\n 'std': (0.229, 0.224, 0.225),\n 'crop_pct': 0.875,\n 'crop_mode': 'center'}"},"metadata":{}}]},{"cell_type":"code","source":"transforms","metadata":{"execution":{"iopub.status.busy":"2024-04-17T20:20:35.415556Z","iopub.execute_input":"2024-04-17T20:20:35.416354Z","iopub.status.idle":"2024-04-17T20:20:35.423847Z","shell.execute_reply.started":"2024-04-17T20:20:35.416324Z","shell.execute_reply":"2024-04-17T20:20:35.422920Z"},"trusted":true},"execution_count":79,"outputs":[{"execution_count":79,"output_type":"execute_result","data":{"text/plain":"Compose(\n    Resize(size=256, interpolation=bicubic, max_size=None, antialias=warn)\n    CenterCrop(size=(224, 224))\n    ToTensor()\n    Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n)"},"metadata":{}}]},{"cell_type":"code","source":"TRAIN_TRANSFORMS = A.Compose([\n        A.HorizontalFlip(p=0.5),\n        A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.25),\n        A.ImageCompression(quality_lower=85, quality_upper=100, p=0.25),\n        A.RandomSizedCrop(\n                [448, 512],\n                CONFIG.IMAGE_SIZE, CONFIG.IMAGE_SIZE, w2h_ratio=1.0, p=0.75),\n        A.Resize(CONFIG.IMAGE_SIZE, CONFIG.IMAGE_SIZE),\n        A.ToFloat(),\n        A.Normalize(mean=CONFIG.IMAGE_MEAN, std=CONFIG.IMAGE_STD, max_pixel_value=1),\n        ToTensorV2(),\n    ])\n\nTEST_TRANSFORMS = A.Compose([\n        A.Resize(CONFIG.IMAGE_SIZE, CONFIG.IMAGE_SIZE, interpolation=cv2.INTER_CUBIC),\n        A.ToFloat(),\n        A.Normalize(mean=CONFIG.IMAGE_MEAN, std=CONFIG.IMAGE_STD, max_pixel_value=1),\n        ToTensorV2(),\n    ])","metadata":{"execution":{"iopub.status.busy":"2024-04-17T18:04:07.193676Z","iopub.execute_input":"2024-04-17T18:04:07.194014Z","iopub.status.idle":"2024-04-17T18:04:07.202669Z","shell.execute_reply.started":"2024-04-17T18:04:07.193987Z","shell.execute_reply":"2024-04-17T18:04:07.201552Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## 3.1. Define architecture","metadata":{}},{"cell_type":"markdown","source":"## 3.2. Define training","metadata":{}},{"cell_type":"markdown","source":"## 3.3. Trainig...","metadata":{}},{"cell_type":"code","source":"train_dataset = CustomDataset(train, test_cols, TRAIN_TRANSFORMS)\n\ntrain_dataloader = DataLoader(\n        train_dataset,\n        batch_size=CONFIG.BATCH_SIZE,\n        shuffle=True,\n        drop_last=True,\n#         num_workers=psutil.cpu_count(),\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-17T18:04:51.479918Z","iopub.execute_input":"2024-04-17T18:04:51.480257Z","iopub.status.idle":"2024-04-17T18:04:51.529059Z","shell.execute_reply.started":"2024-04-17T18:04:51.480232Z","shell.execute_reply":"2024-04-17T18:04:51.527951Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"model = Model().to(DEVICE)\n\nclass AverageMeter(object):\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val):\n        self.sum += val.sum()\n        self.count += val.numel()\n        self.avg = self.sum / self.count\n\nMAE = torchmetrics.regression.MeanAbsoluteError().to(DEVICE)\nR2 = torchmetrics.regression.R2Score(num_outputs=CONFIG.N_TARGETS, multioutput='uniform_average').to(DEVICE)\nLOSS = AverageMeter()\n\nLOSS_FN = nn.SmoothL1Loss() # r2_loss\n\noptimizer = torch.optim.AdamW(\n    params=model.parameters(),\n    lr=CONFIG.LR_MAX,\n    weight_decay=CONFIG.WEIGHT_DECAY,\n)\n\nLR_SCHEDULER = torch.optim.lr_scheduler.OneCycleLR(\n        optimizer=optimizer,\n        max_lr=CONFIG.LR_MAX,\n        total_steps=CONFIG.N_STEPS,\n        pct_start=0.1,\n        anneal_strategy='cos',\n        div_factor=1e1,\n        final_div_factor=1e1,)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T18:04:26.570654Z","iopub.execute_input":"2024-04-17T18:04:26.571480Z","iopub.status.idle":"2024-04-17T18:04:51.478360Z","shell.execute_reply.started":"2024-04-17T18:04:26.571445Z","shell.execute_reply":"2024-04-17T18:04:51.477590Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/801M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e44f27b892e9448ca7cce7be00d2dea6"}},"metadata":{}}]},{"cell_type":"code","source":"print(\"Start Training:\")\nfor epoch in range(CONFIG.N_EPOCHS):\n    model.train()\n        \n    for step, (row_batch, img_batch, y_true) in enumerate(train_dataloader):\n        img_batch = img_batch.to(DEVICE)\n        y_true = y_true.to(DEVICE)\n        t_start = time.perf_counter_ns()\n        y_pred = model(row_batch, img_batch)\n        loss = LOSS_FN(y_pred, y_true)\n        LOSS.update(loss)\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        LR_SCHEDULER.step()\n        \n        print(f'Step\" {step}/{CONFIG.N_STEPS_PER_EPOCH} finished')\n\ntorch.save(model, 'model.pth')","metadata":{"execution":{"iopub.status.busy":"2024-04-17T18:04:51.530362Z","iopub.execute_input":"2024-04-17T18:04:51.530707Z","iopub.status.idle":"2024-04-17T18:07:31.466048Z","shell.execute_reply.started":"2024-04-17T18:04:51.530677Z","shell.execute_reply":"2024-04-17T18:07:31.464740Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Start Training:\nStep\" 0/4913 finished\nStep\" 1/4913 finished\nStep\" 2/4913 finished\nStep\" 3/4913 finished\nStep\" 4/4913 finished\nStep\" 5/4913 finished\nStep\" 6/4913 finished\nStep\" 7/4913 finished\nStep\" 8/4913 finished\nStep\" 9/4913 finished\nStep\" 10/4913 finished\nStep\" 11/4913 finished\nStep\" 12/4913 finished\nStep\" 13/4913 finished\nStep\" 14/4913 finished\nStep\" 15/4913 finished\nStep\" 16/4913 finished\nStep\" 17/4913 finished\nStep\" 18/4913 finished\nStep\" 19/4913 finished\nStep\" 20/4913 finished\nStep\" 21/4913 finished\nStep\" 22/4913 finished\nStep\" 23/4913 finished\nStep\" 24/4913 finished\nStep\" 25/4913 finished\nStep\" 26/4913 finished\nStep\" 27/4913 finished\nStep\" 28/4913 finished\nStep\" 29/4913 finished\nStep\" 30/4913 finished\nStep\" 31/4913 finished\nStep\" 32/4913 finished\nStep\" 33/4913 finished\nStep\" 34/4913 finished\nStep\" 35/4913 finished\nStep\" 36/4913 finished\nStep\" 37/4913 finished\nStep\" 38/4913 finished\nStep\" 39/4913 finished\nStep\" 40/4913 finished\nStep\" 41/4913 finished\nStep\" 42/4913 finished\nStep\" 43/4913 finished\nStep\" 44/4913 finished\nStep\" 45/4913 finished\nStep\" 46/4913 finished\nStep\" 47/4913 finished\nStep\" 48/4913 finished\nStep\" 49/4913 finished\nStep\" 50/4913 finished\nStep\" 51/4913 finished\nStep\" 52/4913 finished\nStep\" 53/4913 finished\nStep\" 54/4913 finished\nStep\" 55/4913 finished\nStep\" 56/4913 finished\nStep\" 57/4913 finished\nStep\" 58/4913 finished\nStep\" 59/4913 finished\nStep\" 60/4913 finished\nStep\" 61/4913 finished\nStep\" 62/4913 finished\nStep\" 63/4913 finished\nStep\" 64/4913 finished\nStep\" 65/4913 finished\nStep\" 66/4913 finished\nStep\" 67/4913 finished\nStep\" 68/4913 finished\nStep\" 69/4913 finished\nStep\" 70/4913 finished\nStep\" 71/4913 finished\nStep\" 72/4913 finished\nStep\" 73/4913 finished\nStep\" 74/4913 finished\nStep\" 75/4913 finished\nStep\" 76/4913 finished\nStep\" 77/4913 finished\nStep\" 78/4913 finished\nStep\" 79/4913 finished\nStep\" 80/4913 finished\nStep\" 81/4913 finished\nStep\" 82/4913 finished\nStep\" 83/4913 finished\nStep\" 84/4913 finished\nStep\" 85/4913 finished\nStep\" 86/4913 finished\nStep\" 87/4913 finished\nStep\" 88/4913 finished\nStep\" 89/4913 finished\nStep\" 90/4913 finished\nStep\" 91/4913 finished\nStep\" 92/4913 finished\nStep\" 93/4913 finished\nStep\" 94/4913 finished\nStep\" 95/4913 finished\nStep\" 96/4913 finished\nStep\" 97/4913 finished\nStep\" 98/4913 finished\nStep\" 99/4913 finished\nStep\" 100/4913 finished\nStep\" 101/4913 finished\nStep\" 102/4913 finished\nStep\" 103/4913 finished\nStep\" 104/4913 finished\nStep\" 105/4913 finished\nStep\" 106/4913 finished\nStep\" 107/4913 finished\nStep\" 108/4913 finished\nStep\" 109/4913 finished\nStep\" 110/4913 finished\nStep\" 111/4913 finished\nStep\" 112/4913 finished\nStep\" 113/4913 finished\nStep\" 114/4913 finished\nStep\" 115/4913 finished\nStep\" 116/4913 finished\nStep\" 117/4913 finished\nStep\" 118/4913 finished\nStep\" 119/4913 finished\nStep\" 120/4913 finished\nStep\" 121/4913 finished\nStep\" 122/4913 finished\nStep\" 123/4913 finished\nStep\" 124/4913 finished\nStep\" 125/4913 finished\nStep\" 126/4913 finished\nStep\" 127/4913 finished\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[22], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m loss \u001b[38;5;241m=\u001b[39m LOSS_FN(y_pred, y_true)\n\u001b[1;32m     11\u001b[0m LOSS\u001b[38;5;241m.\u001b[39mupdate(loss)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"#train_dataset[:100000]","metadata":{"execution":{"iopub.status.busy":"2024-04-17T20:40:27.293964Z","iopub.execute_input":"2024-04-17T20:40:27.294585Z","iopub.status.idle":"2024-04-17T20:40:27.298506Z","shell.execute_reply.started":"2024-04-17T20:40:27.294553Z","shell.execute_reply":"2024-04-17T20:40:27.297573Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"markdown","source":"# 4. Submission","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv(DATAPATH + '/test.csv')\ntest['file_path'] = test['id'].apply(lambda s: DATAPATH + f'/test_images/{s}.jpeg')\ntest['jpeg_bytes'] = test['file_path'].progress_apply(lambda fp: open(fp, 'rb').read())","metadata":{"execution":{"iopub.status.busy":"2024-04-17T17:56:16.983603Z","iopub.status.idle":"2024-04-17T17:56:16.983943Z","shell.execute_reply.started":"2024-04-17T17:56:16.983772Z","shell.execute_reply":"2024-04-17T17:56:16.983786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = CustomDataset(test, ['id'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.1. Run interfarance","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}